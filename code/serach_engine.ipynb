{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"serach_engine.ipynb","provenance":[{"file_id":"190H8S-wwJruLKduQn0gdG-rNonpUbnPN","timestamp":1626296813586}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN+kbL7kXg7n6w8yF+bJk61"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"5UoR44og9e0u","executionInfo":{"status":"ok","timestamp":1626384976018,"user_tz":420,"elapsed":21576,"user":{"displayName":"漏气了","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9OAcNICyclgkTml2mJWyIV5_1NRfibRHA2V_73A=s64","userId":"08159925913877395493"}}},"source":["# set up the environment\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n","\n","import findspark \n","findspark.init(\"spark-2.4.4-bin-hadoop2.7\")# SPARK_HOME\n","\n","from pyspark import SparkContext\n","sc = SparkContext.getOrCreate()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wb45dB5d99oi","executionInfo":{"status":"ok","timestamp":1626384875238,"user_tz":420,"elapsed":16262,"user":{"displayName":"漏气了","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9OAcNICyclgkTml2mJWyIV5_1NRfibRHA2V_73A=s64","userId":"08159925913877395493"}},"outputId":"71882dc2-dfa7-44c7-95ea-cf60278e64a4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dw1iJV5m-Qtf","executionInfo":{"status":"ok","timestamp":1626384936044,"user_tz":420,"elapsed":1733,"user":{"displayName":"漏气了","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9OAcNICyclgkTml2mJWyIV5_1NRfibRHA2V_73A=s64","userId":"08159925913877395493"}},"outputId":"a9eda522-b828-4e4c-d2f8-cfa222fd17cf"},"source":["import nltk\n","nltk.download('stopwords')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"myBjt7JEAb1I"},"source":["# Build the index using a document collection\n","\n","Create an RDD from a text file\n","\n","Each line of the text file becomes an element of the RDD."]},{"cell_type":"code","metadata":{"id":"tkJ9ukGqAfk5","executionInfo":{"status":"ok","timestamp":1626384984456,"user_tz":420,"elapsed":1135,"user":{"displayName":"漏气了","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9OAcNICyclgkTml2mJWyIV5_1NRfibRHA2V_73A=s64","userId":"08159925913877395493"}}},"source":["# wholeTextFiles generates an RDD of pair values, \n","# where the key is the full path of each file, the value is the content of each file\n","# input = sc.wholeTextFiles(\"/content/drive/My\\ Drive/input_docs\");\n","# return [(wholepath, wholetxt), ...]\n","input = sc.wholeTextFiles(\"/content/drive/My Drive/input_doc_all/\");\n","\n","# Now we strip the prefix of filenames and leave only the basename. \n","# e.g. 'file:/content/drive/My Drive/Colab Notebooks/data_spark/input_docs/3.html'\n","# becomes '3.html' \n","import os\n","from bs4 import BeautifulSoup\n","\n","input2 = input.map(lambda x: (int(os.path.basename(x[0]).split(\".\")[0]), x[1]))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlaFhW623zQG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626385266852,"user_tz":420,"elapsed":275914,"user":{"displayName":"漏气了","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9OAcNICyclgkTml2mJWyIV5_1NRfibRHA2V_73A=s64","userId":"08159925913877395493"}},"outputId":"2ad4a3d2-f962-4345-a0cc-5a052b73af47"},"source":["input2.take(1)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(16807, 'What province is Galkayo located in?')]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"6S7OTmFcHcT-"},"source":["# Create RDD of （word，（docid，frqc，tf））"]},{"cell_type":"code","metadata":{"id":"ef3ghmOjHhQj"},"source":["# Doc to wordlist function\n","# The output will be a list of tuples such as \n","# (\"apple\", (3,10,10/20)), \n","# where 3 is docid, \n","# 10 is frequency of \"apple\" in this doc, \n","# 20 is maxf in in this doc.\n","\n","# from bs4 import BeautifulSoup\n","from collections import Counter\n","import re\n","\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","# for a given doc return a list of tuples of the form (w, (docid, freq, freq/maxfreq))\n","def dw(docid, htmltext):\n","  \n","  # Make all words lowercase\n","  cleantext = BeautifulSoup(htmltext).get_text().lower()\n","  # returning result\n","  tokenizedText = re.findall(r\"\\b[a-z]+\\b\",cleantext)\n","\n","  # remove all the stop words, return a list of words\n","  filteredToken = [w for w in tokenizedText \n","                   if not w in stop_words]\n","  # couter words, return a dic\n","  tokenCnt = Counter(filteredToken)\n","\n","  # tokenCnt.most_common(1) return e.g. {('cat', 2)}, 0st row 1 column\n","  maxf = tokenCnt.most_common(1)[0][1]\n","\n","  # create a nwe dic\n","  wdft = dict()\n","\n","  for t in filteredToken:\n","    # frqc returns the count of the word\n","    frqc = tokenCnt[t]\n","\n","    #return a tuple corresponding the word\n","    wdft[t] = (docid,frqc,frqc/maxf)\n","  # return a dic corresponding the word with docid,frqc,frqc/maxf\n","  # e.g.{'cat': (1, 2, 1.0), 'dog': (1, 1, 0.5)}\n","  return wdft\n","# return [('feb', (4, 1, 0.07142857142857142)), ('talking', (4, 1, 0.07142857142857142)),...]\n","word_docid_freq_tf = input2.flatMap(lambda x: [(t,dw(x[0],x[1])[t]) for t in dw(x[0],x[1])])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HKSsHyrgsoEa"},"source":["Now create an RDD as follows \n","\n","e.g. (word, [(did1,freq1,tf1), (did2,freq2,tf2), ...])"]},{"cell_type":"code","metadata":{"id":"4bF5HjkbsrkB"},"source":["word_docid_freq_tf_2=word_docid_freq_tf.groupByKey().map(lambda x : (x[0], list(x[1])))\n","print(word_docid_freq_tf_2.take(2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDvi9Uy7uDQz"},"source":["# We easily obtain idf as 1/len(postinglist_tf)\n","# idf = 1/len(postinglist_tf)\n","# [('feb', [(4, 1, 0.014285714285714285), (1, 1, 0.014285714285714285), (2, 1, 0.04), (5, 1, 0.03333333333333333), (3, 1, 0.06666666666666667)])]\n","word_docid_freq_tfidf= word_docid_freq_tf_2.map(lambda x : (x[0], list(map(lambda y: (y[0], y[1], y[2]/len(x[1])), x[1] ))))\n","print(word_docid_freq_tfidf.take(2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zsShT7Ns2cJz","executionInfo":{"status":"ok","timestamp":1626303752064,"user_tz":420,"elapsed":1316,"user":{"displayName":"漏气了","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9OAcNICyclgkTml2mJWyIV5_1NRfibRHA2V_73A=s64","userId":"08159925913877395493"}},"outputId":"31746a83-90f9-4a4b-dba2-1b9d5770640e"},"source":["# Now, we would like to obtain the magnitude of each doc.\n","# First, produce (did, ( freq,tfidf)) for each word of doc did; \n","# We do don't need the word itself, just its (freq,tfidf). \n","# Then, do reduceByKey on these tuples and obtain maxfreq and \n","# magnitude (squared) for each document. \n","import math;\n","#TODO\n","# RDD of (did,(freq,tfidf)) tuples\n","did_freq_tfidf=word_docid_freq_tfidf.flatMapValues(lambda x:x)\n","print(did_freq_tfidf.take(2))\n","did_freq_tfidf=did_freq_tfidf.map(lambda x:(x[1][0],(x[1][1],x[1][2]*x[1][2])))\n","print(did_freq_tfidf.take(2))\n","# Produce (did,(maxf,magnitudesq))\n","doc_maxf_mag=did_freq_tfidf.reduceByKey(lambda x,y:(max(x[0],y[0]),x[1]+y[1]))\n","print(doc_maxf_mag.take(2))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('solo', (15, 1, 0.058823529411764705)), ('solo', (10, 1, 0.058823529411764705))]\n","[(15, (1, 0.0034602076124567475)), (10, (1, 0.0034602076124567475))]\n","[(10, (1, 0.0038591326840581855)), (14, (1, 0.0035248396701107894))]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uW-Q-BFgGgUE"},"source":["# Save doc2mag and index"]},{"cell_type":"code","metadata":{"id":"PLPW9UcnCiK9"},"source":["!rm -rf inv_idx\n","word_docid_freq_tfidf.repartition(1).saveAsTextFile(\"inv_idx\");"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNf2Zdl5CljT"},"source":["!rm -rf doc_mag\n","doc_maxf_mag.repartition(1).saveAsTextFile(\"doc_mag\");"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FibZxYzsDnKr","executionInfo":{"status":"ok","timestamp":1626304427261,"user_tz":420,"elapsed":849,"user":{"displayName":"漏气了","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9OAcNICyclgkTml2mJWyIV5_1NRfibRHA2V_73A=s64","userId":"08159925913877395493"}},"outputId":"b2536b6d-0e0a-416f-a85a-b4a69ea209bb"},"source":["!ls -lrt inv_idx\n","#!head inv_idx/part-00001\n","#!wc -l inv_idx/part-00000\n","#!wc -l inv_idx/part-00001\n","!cat inv_idx/part-00000 > /content/drive/My\\ Drive/inv_idx.txt\n","!wc -l /content/drive/My\\ Drive/inv_idx.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 2792\n","-rw-r--r-- 1 root root 2855593 Jul 14 23:12 part-00000\n","-rw-r--r-- 1 root root       0 Jul 14 23:12 _SUCCESS\n","12136 /content/drive/My Drive/inv_idx.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rhoNnQadD4ji","executionInfo":{"status":"ok","timestamp":1626304441307,"user_tz":420,"elapsed":898,"user":{"displayName":"漏气了","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9OAcNICyclgkTml2mJWyIV5_1NRfibRHA2V_73A=s64","userId":"08159925913877395493"}},"outputId":"e8596449-0bd5-4290-a46b-ed42a323aa78"},"source":["!ls -lrt doc_mag\n","!head doc_mag/part-00000\n","!wc -l doc_mag/part-00000\n","!wc -l doc_mag/part-00001\n","!cat doc_mag/part-00000 > /content/drive/My\\ Drive/doc_mag.txt\n","!wc -l /content/drive/My\\ Drive/doc_mag.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 580\n","-rw-r--r-- 1 root root 591624 Jul 14 23:12 part-00000\n","-rw-r--r-- 1 root root      0 Jul 14 23:12 _SUCCESS\n","(10, (1, 0.0038591326840581855))\n","(14, (1, 0.0035248396701107894))\n","(2, (1, 0.006177163001462405))\n","(12, (1, 0.006342785118225462))\n","(130, (1, 0.005674244508596622))\n","(134, (1, 0.008530274174313483))\n","(4764, (1, 0.004658267184246462))\n","(68, (1, 0.002070250129949385))\n","(102, (1, 0.06403653109524758))\n","(104, (1, 0.06804660087133721))\n","17807 doc_mag/part-00000\n","wc: doc_mag/part-00001: No such file or directory\n","17807 /content/drive/My Drive/doc_mag.txt\n"],"name":"stdout"}]}]}